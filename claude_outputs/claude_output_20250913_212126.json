{
  "id": "msg_01AcnRzuByxoDjr7G3SzhAkk",
  "type": "message",
  "role": "assistant",
  "model": "claude-opus-4-1-20250805",
  "content": [
    {
      "type": "text",
      "text": "# CS162 Operating Systems and Systems Programming\n## Lecture 10 & 11: Scheduling - Core Concepts and Classic Policies\n\n→ **Goals for Today**\n\nUnderstanding scheduling fundamentals\nWhat makes a good scheduling policy\nExamining existing schedulers and their performance\n\n→ **The Scheduling Loop**\n\nCore scheduling decisions:\n1. Which task to run next\n2. How frequently does the loop run\n3. What happens if run never returns\n\n```\nif (readyThreads(TCBs)) {\n    nextTCB = selectThread(TCBs);\n    run(nextTCB);\n} else {\n    run_idle_thread();\n}\n```\n\n→ **Thread Life Cycle**\n\nStates: Running → Ready → Blocked → Dying\nTransitions triggered by:\n- Time slice expiration\n- I/O requests\n- Fork/yield operations\n- Interrupt occurrences\n\n→ **Important Performance Metrics**\n\n**Response time (latency)** - User-perceived time to complete task\n**Throughput** - Rate at which tasks are completed  \n**Scheduling overhead** - Time to switch between tasks\n**Predictability** - Variance in response times\n**Fairness** - Equality in performance perceived by tasks\n**Starvation** - Lack of progress due to resource allocation\n\n→ **Scheduling Policy Goals**\n\nMinimize latency\nMaximize throughput\nRemain fair and starvation-free\n\n→ **Useful Metrics**\n\n**Waiting time for P** - Total time spent waiting for CPU\n**Average waiting time** - Average of all processes' wait time\n**Response time for P** - Time to when process gets first scheduled\n**Completion time** - Waiting time + Run time\n**Average completion time** - Average of all processes' completion time\n\n→ **Core Assumptions**\n\nThreads are independent (one thread = one user)\nOnly work-conserving schedulers (never leave processor idle if work exists)\n\n→ **Workload Types**\n\n**Compute-Bound** - Primarily perform compute, fully utilize CPU\n**I/O Bound** - Mostly wait for I/O, limited compute in bursts, often blocked\n\n## Classic Scheduling Policies\n\n→ **First-Come, First-Served (FCFS)**\n\nRun tasks in order of arrival\nRun until completion (or blocks on I/O)\nNo preemption\n\nExample with P1(3), P2(3), P3(24):\n- Order P1→P2→P3: Average completion = 13, Average waiting = 3\n- Order P3→P2→P1: Average completion = 27, Average waiting = 17\n\n**The Convoy Effect**\nShort processes stuck behind long processes\nLots of small tasks build up behind long tasks\nFCFS is non-preemptible\n\n**FCFS Summary**\nGood: Simple, low overhead, no starvation*\nBad: Sensitive to arrival order (poor predictability)\nUgly: Convoy effect, bad for interactive tasks\n*Assuming jobs eventually finish\n\n→ **Shortest Job First (SJF)**\n\nSchedule jobs by estimated completion time\nMinimizes average completion time if all jobs arrive simultaneously\n\nExample with P1(3), P2(6), P3(24), P4(1):\nOrder P4→P1→P2→P3: Average completion = 12.25\n\n**SJF Issues**\nCan lead to starvation - always favoring short jobs\nSubject to convoy effect - non-preemptible\nRequires knowing job duration\n\n**SJF Summary**\nGood: Optimal average completion time (simultaneous arrival)\nBad: Still subject to convoy effect\nUgly: Can lead to starvation, requires job duration knowledge\n\n→ **Shortest Time to Completion First (STCF)**\n\nIntroduces preemption\nSchedule task with least time remaining\nDe-schedules running tasks before completion\n\n**STCF Summary**\nGood: Optimal average completion time always\nBad: -\nUgly: Can lead to starvation, requires job duration knowledge\n\n→ **Round-Robin (RR)**\n\nRuns job for time slice (scheduling quantum)\nAfter time slice, switch to next job in ready queue\nTime-slicing approach\n\nExample with quantum = 20:\nP1(53), P2(8), P3(68), P4(24)\nSchedule: P1→P2→P3→P4→P1→P3→P4→P1→P3→P3\nAverage waiting = 66.25, Average completion = 104.25\n\n**Time Quantum Effects**\nSmaller quantum → Better response time, worse completion time\nLarger quantum → Better completion time, worse response time\nMust be large relative to context switch overhead\n\n**Context Switching Overhead**\nMode switch overhead\nCache state thrashing\nQuantum must exceed context switch time\n\n**RR Summary**\nGood: Bounded response time, no starvation, no convoy effect\nBad: High completion time (stretches long jobs)\nUgly: Context switching overhead\n\n→ **Performance Comparison**\n\nFCFS vs RR with 10 jobs (100s each), quantum = 1s:\n- FCFS completion times: 100, 200, ..., 1000\n- RR completion times: 991, 992, ..., 1000\n\n## Advanced Scheduling\n\n→ **Priorities**\n\nJobs assigned priority levels\nHigher priority jobs scheduled first\nShould get larger CPU share\n\n**Strict Priority Scheduling**\nn different priority queues\nAlways process highest-priority non-empty queue\nProcess each queue round-robin\nCan lead to starvation\n\n**Priority Inversion**\nHigh-priority thread blocked waiting on low-priority thread\nLow-priority holds resource needed by high-priority\nMedium-priority can starve high-priority\n\n**Priority Donation/Inheritance**\nHigh-priority temporarily grants priority to low-priority\nAllows low-priority to release needed resources\n\n→ **Multi-Level Feedback Queue (MLFQ)**\n\nCreates distinct queues with different priority levels\nJobs belong to one queue at a time\nJobs can move between queues\nIndividual queues run RR with increasing time quanta\n\n**MLFQ Rules (Version 2.0)**\n\nRule 1: If Priority(A) > Priority(B), A runs\nRule 2: If Priority(A) = Priority(B), run RR\nRule 3: New jobs start at highest priority\nRule 4: Job using full time allotment drops priority\nRule 5: After period S, move all jobs to top queue\n\n**Learning Behavior**\nAssumes all jobs short initially\nI/O-bound jobs stay at high priority\nCPU-bound jobs drop to lower priorities\nEmulates STCF without knowing job duration\n\n**MLFQ Issues and Solutions**\nGaming: Insert I/O before quantum expires\nSolution: Track total time at priority level\n\nStarvation: High-priority queues favored\nSolution: Periodic priority boost (Rule 5)\n\n## Linux Schedulers\n\n→ **History**\n\nO(n) scheduler: Linux 2.4 to 2.6\nO(1) scheduler: Linux 2.6 to 2.6.22\nCompletely Fair Scheduler (CFS): Linux 2.6.23 to 6.6\nEEVDF scheduler: Linux 6.6 onwards\n\n→ **O(n) Scheduler**\n\nScans full ready queue at context switch\nComputes priorities dynamically\nSingle queue even on multicore\nScalability issues with process count\n\n→ **O(1) Scheduler**\n\nConstant time process selection\n140 priority levels:\n- Kernel/real-time: 0-99 (0 highest)\n- User tasks: 100-139 (100 highest)\n\nPer-CPU dual ready queues:\n- Active queue: processes with remaining quanta\n- Expired queue: processes with exhausted quanta\n\nPriority adjustment ±5 based on sleep_avg heuristic\nInteractive credit for I/O-bound behavior\n\n→ **Real-Time Scheduling**\n\nGoal: Predictability of performance\nReal-time tasks preempt non-RT tasks\nNo dynamic priority adjustment\n\nSchemes:\n- SCHED_FIFO: Preempts others, no timeslice limit\n- SCHED_RR: Round-robin among same priority\n\nReal-time equals predictability, not fast computing"
    }
  ],
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 17784,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "cache_creation": {
      "ephemeral_5m_input_tokens": 0,
      "ephemeral_1h_input_tokens": 0
    },
    "output_tokens": 1929,
    "service_tier": "standard"
  }
}